{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "dauF4eBmngu3",
        "MSa1f5Uengrz",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "gCFgpxoyphqP",
        "lssrdh5qphqQ",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "Ou-I18pAyIpj",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "TNVZ9zx19K6k",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "T5CmagL3EC8N",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "OB4l2ZhMeS1U",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/121deepti/bike-sharing-demand-prediction/blob/main/Bike_Sharing_Demand_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**  -Bike Sharing Demand Prediction \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project is on the prediction of Bike Rental Demand in Seoul(South Korea).The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.This project is based on supervised learning approach regrssion problem.It follows all the assumptions of regression model.The dependent variable is of course the Rented Bike Count and other features are independent variables.\n",
        "There are several steps in completing this project.First checked the distribution of data and find the symmetricity and skewness and take corrective measures.\n",
        "Then ckecked for outliers and deal with them.After dealing with multicollinerity and done with scaling divide the dataset into train test and fit into Linear Regression model,Ridge Regression,Lasso Regression and Random Forest Regressor and check their results using different Evaluation metrics.\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/121deepti/bike-sharing-demand-prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import files\n",
        "file=files.upload()"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df=pd.read_csv(io.BytesIO(file['SeoulBikeData.csv']),encoding= 'unicode_escape')"
      ],
      "metadata": {
        "id": "bixMmWo_flQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "bike_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.tail()"
      ],
      "metadata": {
        "id": "Gdwu9zxuAWhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "bike_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(bike_df[bike_df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "bike_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sn.heatmap(data=bike_df.isnull(),cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset belongs to bike sharing demand information so we have to find insights from this data about the predicted demand of bikes for rent.There are 8760 rows and  14 columns.\n",
        "There are no duplicate and null values in the dataset."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "bike_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe 'all' includes all the columns including catergorical\n",
        "bike_df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Date: Date of when bike is rent out\n",
        "### Rented Bike Count: Total Bike rent out(Target feature)\n",
        "### Hour:Bike rent out in which hour of day(0-23)\n",
        "### Temperature(°C):Temp of the bike rent out day in centigrade\n",
        "### Humidity(%):Humidity on that day in %age form\n",
        "### Solar Radiation (MJ/m2):Solar radiation measure on that day\n",
        "### Rainfall:Rain fall on that day\n",
        "### Snowfall:Snow fall on that day\n",
        "### Seasons:Contains season info(Spring,Summer,Autumn,Winter)\n",
        "### Holiday:that day was a public holiday or not(excluding weekends i.e. Saturday and Sundays)\n",
        "### Functioning day:That day was a working day or not.\n",
        "### Wind Speed: Wind Speed on that day\n",
        "### Visibility: Maximum visibility(per 10 m)\n",
        "### Dew Point Temperature: Dew point Temp (degree C)"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in bike_df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",bike_df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Renaming Columns"
      ],
      "metadata": {
        "id": "sN8l_ZPtCDGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Make a seperate copy of data frame\n",
        "df=bike_df.copy()"
      ],
      "metadata": {
        "id": "q1YemYhnNVI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Renaming column name by removing their units and spaces for easy understanding and analysis\n",
        "df.rename(columns={'Temperature(°C)':'Temperature','Humidity(%)':'Humidity','Solar Radiation (MJ/m2)':'Solar_Radiation',\n",
        "                       'Rainfall(mm)':'Rainfall','Snowfall (cm)':'Snowfall','Wind speed (m/s)':'Wind_speed',\n",
        "                       'Visibility (10m)':'Visibility','Dew point temperature(°C)':'Dew_point_temperature','Rented Bike Count':\n",
        "                       'Rented_Bike_Count','Functioning Day': 'Functioning_day'}\n",
        "                       ,inplace=True)"
      ],
      "metadata": {
        "id": "EuyPV1ujCBW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#Creating a copy of dataframe\n",
        "df_cpy=df.copy()\n",
        "#Finding the range of date column\n",
        "df_cpy['Date'].unique()\n",
        "#By this we came to know that date lies between 01/12/2017 and 30/11/2018 i.e. around one year that means we only need to analyse month level data."
      ],
      "metadata": {
        "id": "d6mDXiQyq9eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing datatype of Date feature from object to date type and deriving Day and Month columns from Date column \n",
        "df_cpy.Date=pd.to_datetime(df_cpy.Date,format='%d/%m/%Y')\n",
        "df_cpy['Year'] = df_cpy['Date'].dt.year\n",
        "df_cpy['Month'] = df_cpy['Date'].dt.month_name()\n",
        "df_cpy.head()"
      ],
      "metadata": {
        "id": "Jw0mEQEwrJgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the year value\n",
        "df_cpy['Year'].value_counts()"
      ],
      "metadata": {
        "id": "iBP_jHRI-20j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Average Bike demand on  monthly basis\n",
        "df_cpy.groupby(['Month'])['Rented_Bike_Count'].mean().reset_index(name=\"Avg Rented Bike Count\")"
      ],
      "metadata": {
        "id": "_yOpv6oI61ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top 5 Bike demand on hourly and monthly basis.\n",
        "df_cpy.groupby(['Month','Hour'])['Rented_Bike_Count'].mean().nlargest().reset_index(name=\"Avg Rented Bike Count\")"
      ],
      "metadata": {
        "id": "pM8M-nt98kKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top 5 Bike demand on hourly basis.\n",
        "df_cpy.groupby(['Hour'])['Rented_Bike_Count'].mean().nlargest().reset_index(name=\"Avg Rented Bike Count\")"
      ],
      "metadata": {
        "id": "XgAc-49xr7vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bike demand on holiday v/s no holiday monthly basis\n",
        "df_cpy.groupby(['Month','Holiday'])['Rented_Bike_Count'].mean().reset_index(name=\"Avg Rented Bike Count\")"
      ],
      "metadata": {
        "id": "cRRDj1Mk8x3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bike demand on functioning/nonfunctioning day on monthly basis\n",
        "df_cpy.groupby(['Month','Functioning_day'])['Rented_Bike_Count'].mean().reset_index(name=\"Avg Rented Bike Count\")"
      ],
      "metadata": {
        "id": "gwXMlSPZ-PBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bike demand on holiday v/s on holiday hourly basis\n",
        "df_cpy.groupby(['Hour','Holiday'])['Rented_Bike_Count'].mean().reset_index(name=\"Avg Rented Bike Count\")"
      ],
      "metadata": {
        "id": "-1fEjADmsDC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top 5 Bike demand in each season\n",
        "df_cpy.groupby(['Seasons'])['Rented_Bike_Count'].mean().nlargest().reset_index(name=\"Avg Rented Bike Count\")"
      ],
      "metadata": {
        "id": "4trbpyffsQFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bike demand on functioning/nonfunctioning day on hourly basis\n",
        "df_cpy.groupby(['Hour','Functioning_day'])['Rented_Bike_Count'].mean().reset_index(name=\"Avg Rented Bike Count\")"
      ],
      "metadata": {
        "id": "tT-HQ4ausWW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bike Demand on Functioning v/s Non Functioning day\n",
        "df_cpy.groupby(['Functioning_day'])['Rented_Bike_Count'].mean().reset_index(name=\"Avg Rented Bike Count\")"
      ],
      "metadata": {
        "id": "wRcoVJkPsdTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide the dataset based on Rented Bike Count\n",
        "df_zero_cnt=df_cpy[df_cpy['Rented_Bike_Count']==0]\n",
        "df_nonzero_cnt=df_cpy[df_cpy['Rented_Bike_Count']!=0]"
      ],
      "metadata": {
        "id": "uNlYtAa97Gkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Derive the statiscs when Rented Bike Count is 0\n",
        "df_zero_cnt.describe(include='all')"
      ],
      "metadata": {
        "id": "C9gh8B0k8r_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Statistics when Rented Bike count is nonzero\n",
        "df_nonzero_cnt.describe(include='all')"
      ],
      "metadata": {
        "id": "BgoT04Cf8s0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here,I have changed the data type of date column  and fetch column 'Month' and 'Year',also rename some columns for further analysis. \n",
        "  In the season of summer (May,June,July) and at 18th,19th hour when there is no holiday ,there is high bike demand.\n",
        "In Summer season there is highest number of demand and in winter(Dec,Jan,Feb) the demand is very less.\n",
        "There is no demand of bikes in case of Non Functioning day.\n",
        "We analyze the features when Rented Bike Count is 0 and when the demand is nonzero."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Making seperate list of numerical columns and removing target variable from the list\n",
        "numerical_cols=df.describe().columns.tolist()\n",
        "numerical_cols.remove(\"Rented_Bike_Count\")\n",
        "print(numerical_cols)"
      ],
      "metadata": {
        "id": "vG0HEpNJMbiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making seperate list of categorical columns\n",
        "categorical_cols=df.describe(include=['object','category']).columns.tolist()\n",
        "print(categorical_cols)"
      ],
      "metadata": {
        "id": "djdK-UB-Mpad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1  Distribution of Depenedent variable"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(7,7))\n",
        "ax=fig.gca()\n",
        "sn.distplot(df_cpy.Rented_Bike_Count)\n",
        "ax.set_title(\"skewness \"+str(df_cpy['Rented_Bike_Count'].skew()))"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart is useful in analysis of distribution of target variable."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart shows the distribution of target variable i.e. Rented_bike_count. It is clear that the distribution is highly right skewed. "
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to highly skewed data,it is difficult for an investor to predict the trend in the data set."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2  Dependent variable after reducing skewness"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 \n",
        "fig=plt.figure(figsize=(7,7))\n",
        "ax=fig.gca()\n",
        "sn.distplot(np.sqrt(df_cpy.Rented_Bike_Count))\n",
        "ax.set_title(\"skewness \"+str(np.sqrt(df_cpy['Rented_Bike_Count']).skew()))"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want to see the result after handling skewness"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying square root transformation y variable is now having low skewness and looking nearly normally distributed."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it is easy to find the trend of data after transformation."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3  Plot histogram for each numerical column"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(10,7))\n",
        "for index,item in enumerate(numerical_cols):\n",
        "  plt.subplot(3,3,index+1)\n",
        "  feature=df[item]\n",
        "  sn.distplot(df[item])\n",
        "  sk=round(feature.skew(),2)\n",
        "  ax=fig.gca()\n",
        "  ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "  ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)    \n",
        "  ax.set_title(item+'  skewness'+str(sk))\n",
        "plt.tight_layout() "
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These charts help us in analyzing the differnt numerical features distribution"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can conclude the following points\n",
        "1.   \"Temperature\" column has low negatively skewed data that means +ve increase in temp has more weight in comparision to -ve temperature\n",
        "2.  \"Humidity\" column has almost normal distribution that means data is evenly distributed.\n",
        "3.  \"Wind_speed\" column has high postively skewed data that means our data is around low wind speed.\n",
        "4.   \"Visibility\" column has highly negative skewed data that symbolizes the assumption of distribution of data around high visibility.\n",
        "5.  \"Dew Point Temperature\" column has slightly negative skewed data that means \n",
        "more weightage is given to high temp.\n",
        "6.  \"Solar radiation\" has highly positive skewed data that reflects the fact that most of the data is distributed around 0 and 0.5\n",
        "7. \"Rainfall\" is very high postively skewed data~ 14 that signifies the data is distributed between 0 to 3(approx.).\n",
        "8.  \"Snowfall\" is also a highly postively skewed data that most of the data is distributed around 0 and 1.\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights help us to know about the distribution of data of numeric features that help us to know the properties of data."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 Boxplot Analysis of numerical variables"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(8,7))\n",
        "for index,item in enumerate(numerical_cols):\n",
        "  plt.subplot(3,3,index+1)\n",
        "  ax=fig.gca()\n",
        "  df.boxplot(column=item)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart is to show distributions of numeric data values.They are built to provide high-level information at a glance, offering general information about a group of data’s symmetry, skewness, variance, and outliers"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highlights of this chart are:\n",
        "1.  Hour,Temperature,Dew point temperature and Humidity have symmetrical distrubution of data, no outliers can be seen.\n",
        "2.  In Wind Speed the data is skewed,as lot of outliers are present above the IQR.\n",
        "3. Visibility column has skewness present in data,but no outliers can be seen.\n",
        "4. Solar Radiation column has highly skewed data and a lot of outliers are present in the dataset.\n",
        "5.  Rainfall and Snowfall has very highly skewed data and that's why a large number of outliers are present."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just a box plot cannot define business impact. It's done just to see the distribution of the column data over the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5  Finding the relationship between dependent and independent numerical variables"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8, 7))\n",
        "for index,item in enumerate(numerical_cols):\n",
        "  plt.subplot(3,3,index+1)\n",
        "  ax = fig.gca()\n",
        "  feature = df[item]\n",
        "  label = df['Rented_Bike_Count']\n",
        "  correlation = round(feature.corr(label),2)\n",
        "  plt.scatter(x=feature, y=label)\n",
        "  plt.xlabel(item)\n",
        "  plt.ylabel('Rented Bikes Count')\n",
        "  ax.set_title('Rented Bikes count--' + item + '- correlation: ' + str(correlation),fontsize=6)\n",
        "  z = np.polyfit(df[item], df['Rented_Bike_Count'], 1)\n",
        "  y_hat = np.poly1d(z)(df[item])\n",
        "  plt.plot(df[item], y_hat, \"r--\", lw=1)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart helps in analysing the relationship between dependent and indendedent numerical variables."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the highlights:\n",
        "1. \"Wind speed\",\"Visibility\",\"Dew point Temperature\" and \"Solar Radiation\" have +ve correlation with dependent variable i.e. rental bike demand is increased with increase of these features\n",
        "2. \"Temperature\" has high +ve correlation with the dependent variable that means increase in temperature implies increase in demand. .\n",
        "3. \"Humidity\",\"Rainfall\" and \"Snowfall\" have weak negative correlation with the target variable that means demand decreses with the increase of these features."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart is very useful in further analysis as we have find out important features so can make right predictions."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Chart -6 Pair Plot of numerical variables"
      ],
      "metadata": {
        "id": "sAhdQQ4aYl9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sn.pairplot(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YIsye6jsYFKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "hNa4SC4lY7Sk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot helps in better analysis of numeric features pairwise."
      ],
      "metadata": {
        "id": "y8E39PFcZcj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "P_7D3tMTZybf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The findings are-\n",
        "The Rented bike count is positively correlated with the Temperature.Humidity is slightly negative correlated with Wind speed. Visibility and Humidity has negative correlation.Solar radition and Humidity has slightly negative correlation.\n"
      ],
      "metadata": {
        "id": "bNvoX4bBaE9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7  Correlation Heatmap"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "correlation = df.corr()\n",
        "sn.heatmap(abs(correlation), annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart helps to understand the relation between all numerical columns."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  There is a very strong relation between Temperature and Dew point Temperature.\n",
        "2.  Visibility and Dew point Temperature has a relation with Humidity."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart will help us to find multicollinerity among independent features that increases the complexity of the model and make predictions worse."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Analysis of Categorical Data**"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In statistics, a categorical variable is a variable that can take on one of a limited, and usually fixed, number of possible values, assigning each individual or other unit of observation to a particular group or nominal category on the basis of some qualitative property."
      ],
      "metadata": {
        "id": "plKLTWCUFm5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Chart 7: Count plot for each categorical feature count"
      ],
      "metadata": {
        "id": "USbq6s0DLuYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in categorical_cols:\n",
        "  fig = plt.figure(figsize=(8, 5))\n",
        "  ax = fig.gca()\n",
        "  sn.countplot(x =col, data = df)\n",
        "  for p in ax.patches:\n",
        "   ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tQ2mtW6eNHrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want to know the frequency distribution of categorical features."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pin points are:\n",
        "*   All the Seasons have almost equal number of data points.\n",
        "*   There are less data points for holiday in comparison to normal days and same with Functioning day and non functioning day.\n",
        "*   For all Hours number of data points are the same."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data distribution doesn't impact our business much. "
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8  Plot a BoxPlot for the label by each categorical feature  "
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols"
      ],
      "metadata": {
        "id": "BvOyUW0h3OZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(7, 6))\n",
        "for index,col in enumerate(categorical_cols):\n",
        "    ax = fig.gca()\n",
        "    plt.subplot(2,2,index+1)\n",
        "    sn.boxplot(x=col,y='Rented_Bike_Count',data=df)\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart shows the outliers present in our data set."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Date column has a large number of values and many outliers are present in the dataset.\n",
        "In case of Season column,there are lot of values are present beyond the IQR and records for summer>autumn>spring>winter.\n",
        "The Holiday column has outliers in the dataset, in case of holiday there is skewness present in the data as well.\n",
        "Outliers well as skewness is present in the Functioning_day column. "
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These outliers should be handled cautiously as these can change our model and predictions completely."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9  Relationship between categorical and dependent variable "
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "for col in categorical_cols:\n",
        "  fig = plt.figure(figsize=(7 ,7))\n",
        "  ax = fig.gca()\n",
        "  sn.set(style=\"ticks\")\n",
        "  sn.pointplot(x=col, y=\"Rented_Bike_Count\", data=df)\n",
        "  plt.grid()\n",
        "  plt.show() \n",
        " "
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart shows the relation of independent categorical variables and target variable."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highlights are-\n",
        "*   The demand of rental bike is increased around 8 a.m. and 6 p.m. as these are the hours when people go and come back from office.\n",
        "*   In summer season ,the demand of bike is the highest while during spring and autumn it remains almost same but during winters the demand is very less.\n",
        "*   On holidays there is very less demand ,which is obvious.\n"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights can help us better know about the data which help us to make predictions better."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 Hourly demand of Rented bike on holidays v/s nonholidays "
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df_cpy.groupby(['Hour','Holiday'])['Rented_Bike_Count'].mean().unstack()\n",
        "df1.plot(kind='bar')\n",
        "plt.legend([\"Holiday\", \"No Holiday,\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart gives the approximation of hourly bike demand on holidays and on nonholidays."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is always a high demand incase of non holiday but the difference in demand between holiday and nonholiday is very high between 7-9 am and after 5 pm onwards."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "tNM2wEYEdWae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Yes it is always good to know previously about sudden demand so there is always be a provision for accomplishing these demands"
      ],
      "metadata": {
        "id": "0vFF017SdYJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Creating parameter class"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from scipy import stats\n",
        "from scipy.stats import norm\n",
        "class z_score:\n",
        "  def mean(self,hyp,sample,size,std):\n",
        "    return (sample - hyp)*math.sqrt(size)/std\n",
        "  def var(self,hyp,sample,size):\n",
        "    return (size-1)*sample/hyp\n",
        "  def proportion(self,sample,hyp,size):\n",
        "    return (sample - hyp)/math.sqrt(hyp*(1-hyp)/size)\n",
        "variance = lambda x : sum([(i - np.mean(x))**2 for i in x])/(len(x)-1)\n",
        "z_cum_dis_fun = lambda x: norm(0,1).cdf(x)\n",
        "# Creating a function for getting P value\n",
        "def p_value(z,tailed,t,hypothesis_number,df,col):\n",
        "  if t!=\"true\":\n",
        "    z=z_cum_dis_fun(z)\n",
        "    if tailed=='l':\n",
        "      return z\n",
        "    elif tailed == 'r':\n",
        "      return 1-z\n",
        "    elif tailed == 'd':\n",
        "      if z>0.5:\n",
        "        return 2*(1-z)\n",
        "      else:\n",
        "        return 2*z\n",
        "    else:\n",
        "      return np.nan\n",
        "  else:\n",
        "    z,p_value=stats.ttest_1samp(df[col],hypothesis_number)\n",
        "    return p_value\n",
        "  \n",
        "# Conclusion about the P - Value\n",
        "def conclusion(p):\n",
        "  significance_level = 0.05\n",
        "  if p>significance_level:\n",
        "    return f\"Failed to reject the Null Hypothesis for p = {p}.\"\n",
        "  else:\n",
        "    return f\"Null Hypothesis rejected Successfully for p = {p}\"\n",
        "\n",
        "# Initializing the class\n",
        "z_score = z_score()"
      ],
      "metadata": {
        "id": "cIevjIbDK_v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1\n",
        "There is no bike rental demand when the average temp is atmost 15. "
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis: H0: mean = 15 Alternate Hypothesis: H1: mean >15 Test-type: Right Tailed Test"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "hypo1=df[(df['Rented_Bike_Count']==0 )]\n",
        "# Getting the required parameter values for hypothesis testing\n",
        "hypothesis_number = 10\n",
        "sample_mean = int(hypo1[\"Temperature\"].mean())\n",
        "size = len(hypo1)\n",
        "std=(variance(hypo1[\"Temperature\"]))**0.5"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Z value\n",
        "z = z_score.mean(hypothesis_number,sample_mean,size,std)\n",
        "# Getting P - Value\n",
        "p = p_value(z=z,tailed='r',t=\"false\",hypothesis_number=hypothesis_number,df=hypo1,col=\"Temperature\")\n",
        "# Getting Conclusion\n",
        "print(z)\n",
        "print(conclusion(p))"
      ],
      "metadata": {
        "id": "QLONC2OrTkkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used Z-Test as the statistical testing to obtain P-Value and found that we failed to reject the null hypothesis and there is no demand of bikes when average temperature is 16 maximum."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing code of hist plot for required columns to know the data distibution\n",
        "fig=plt.figure(figsize=(9,6))\n",
        "ax=fig.gca()\n",
        "feature= (hypo1[\"Temperature\"])\n",
        "sn.distplot(hypo1[\"Temperature\"])\n",
        "ax.axvline(feature.mean(),color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(feature.median(),color='cyan', linestyle='dashed', linewidth=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HB90o6Ktce7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown in the figure the mean is approximately same as the median. Thus, it is a Normal Distribution. That's why I have used Z-Test directly."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2\n",
        "There is no bike demand when the average Humidity is atleast 50."
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis: H0: mean = 50 Alternate Hypothesis: H1: mean <50 Test-type: Left Tailed Test"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypo2=df[(df['Rented_Bike_Count']==0 )]\n",
        "# Getting the required parameter values for hypothesis testing\n",
        "hypothesis_number = 50\n",
        "sample_mean = int(hypo1[\"Humidity\"].mean())\n",
        "size = len(hypo1)\n",
        "std=(variance(hypo1[\"Humidity\"]))**0.5"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Z value\n",
        "z = z_score.mean(hypothesis_number,sample_mean,size,std)\n",
        "# Getting P - Value\n",
        "p = p_value(z=z,tailed='l',t=\"false\",hypothesis_number=hypothesis_number,df=hypo2,col=\"Humidity\")\n",
        "# Getting Conclusion\n",
        "print(conclusion(p))"
      ],
      "metadata": {
        "id": "QXbOrYN8-xQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used Z-Test as the statistical testing to obtain P-Value and we failed to reject the Null hypothesis and can conclude that there is no demand for bikes when Humidity is not atleast 50."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(9,6))\n",
        "ax=fig.gca()\n",
        "feature= (hypo2[\"Humidity\"])\n",
        "sn.distplot(hypo2[\"Humidity\"])\n",
        "ax.axvline(feature.mean(),color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(feature.median(),color='cyan', linestyle='dashed', linewidth=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YxXCd_5mzzfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown in the figure the mean is approximately same as the median. Thus, it is a Normal Distribution. That's why I have used Z-Test directly."
      ],
      "metadata": {
        "id": "1mGoq5CD1Y_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3\n",
        "The average Solar Radiation is 0.6 when there is no demand for bike"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H0: mean=0.6\n",
        "H1: mean!=0.6\n",
        "Test:Two-Tailed test"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import math\n",
        "hypo3=df[(df[\"Rented_Bike_Count\"]==0)]\n",
        "# Getting the required parameter values for hypothesis testing\n",
        "hypothesis_number =0.6\n",
        "sample_mean = round((hypo3[\"Solar_Radiation\"].mean()),2)\n",
        "size = len(hypo3)\n",
        "std=(variance(hypo3[\"Solar_Radiation\"]))**0.5\n",
        "sample_mean"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Z value\n",
        "z = z_score.mean(hypothesis_number,sample_mean,size,std)\n",
        "# Getting P - Value\n",
        "p = p_value(z=z,tailed='d',t=\"false\",hypothesis_number=hypothesis_number,df=hypo3,col=\"Solar_Radiation\")\n",
        "# Getting Conclusion\n",
        "print(conclusion(p))"
      ],
      "metadata": {
        "id": "QmJ2A6FvJMWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used T-Test as the statistical testing to obtain P-Value and found the result that we failed to reject the Null hypothesis and can conclude that when Solar Radiation is 0.6 there is no bike demand. "
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(9,6))\n",
        "ax=fig.gca()\n",
        "feature= (hypo3[\"Solar_Radiation\"])\n",
        "sn.distplot(hypo3[\"Solar_Radiation\"])\n",
        "ax.axvline(feature.mean(),color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(feature.median(),color='cyan', linestyle='dashed', linewidth=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bvCW74e96FQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart we can say that  the distribution is postively skewed. For a skewed data Z-Test can't be performed.\n",
        "So, for a skewed data we can use T-test for better result. Thus, I used t - test."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a copy of the dataset for further feature engineering\n",
        "df_cpy=df.copy()"
      ],
      "metadata": {
        "id": "kr4h1h4Yp6Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df_cpy.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing value present in our data."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "#Outlier Treatment of Numerical values\n",
        "df_cpy.Hour=df_cpy.Hour.astype(\"category\")\n",
        "df_cpy.Date=pd.to_datetime(df_cpy.Date,format='%d/%m/%Y')"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining upper and lower boundry\n",
        "def outlier_treatment_skew(df,feature):\n",
        "  IQR= df[feature].quantile(0.75)- df[feature].quantile(0.25)\n",
        "  lower_bridge =df[feature].quantile(0.25)-1.5*IQR\n",
        "  upper_bridge =df[feature].quantile(0.75)+1.5*IQR\n",
        "  return upper_bridge,lower_bridge"
      ],
      "metadata": {
        "id": "nOvDZWXnY1op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restricting the data to lower and upper boundry\n",
        "for feature in df_cpy.describe().columns:\n",
        "    #Skipping Rented bike count,Rainfall,Snowfall as assumed that Rain and Snow fall are practically not in defined range.\n",
        "  if feature not in['Rented_Bike_Count','Rainfall', 'Snowfall']:\n",
        "    u,l=outlier_treatment_skew(df_cpy,feature)\n",
        "    df_cpy.loc[df_cpy[feature]<=l,feature]=l\n",
        "    df_cpy.loc[df_cpy[feature]>=u,feature]=u"
      ],
      "metadata": {
        "id": "dyJQzQvQZJGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After Outlier Treatment showing the dataset distribution using strip plot\n",
        "# Visualising  code for the numerical columns \n",
        "for col in df_cpy.describe().columns:\n",
        "  fig=plt.figure(figsize=(9,6))\n",
        "  sn.stripplot(df_cpy[col])"
      ],
      "metadata": {
        "id": "HaP3j1ZBZq2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![download.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "V4Dq-OL-EJtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I find the IQR then check the boundary values with first quantile(.25)*1.5IQR for lower boundary and third quantile(.75)*1.5 IQR for Upper boundary.\n",
        "Then for those values that are below the lower boundary and those that are above the upper boundary , replaced with lower and upper boundary respectively."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cpy.columns"
      ],
      "metadata": {
        "id": "z9jXCC-e6wMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dummy Encoding of column Holiday\n",
        "df_cpy.Holiday=df_cpy.Holiday.replace(['No Holiday','Holiday'],[1,0])"
      ],
      "metadata": {
        "id": "QdjI9XIp5UVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dummy Encoding of column Functioning day\n",
        "df_cpy.Functioning_day=df_cpy.Functioning_day.replace(['Yes','No'],[1,0])"
      ],
      "metadata": {
        "id": "poIUsP1O6jDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "def one_hot_encoding(df,feature):\n",
        "  df=pd.concat([df,pd.get_dummies(df[feature],prefix=feature,drop_first=True)],axis=1)\n",
        "  df.drop(feature,axis=1,inplace=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cpy.describe(include=['object','category']).columns"
      ],
      "metadata": {
        "id": "lLuvcf5j7AEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply One Hot Encoding to Hour and Seasons columns\n",
        "for col in df_cpy.describe(include=['object','category']).columns:\n",
        "  df_cpy=one_hot_encoding(df_cpy,col)"
      ],
      "metadata": {
        "id": "6GXyp7BCe9yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cpy.info()"
      ],
      "metadata": {
        "id": "wefO5MPj7ZHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used two techniques for handling categorical data. For Holiday and Functioning day i used dummification techinique. \n",
        "As the column Hour has a specific range(0-23)so i considered it as categorical variable and i decided to use OneHotEncoding(OHE) to Hour and Seasons columns that means i created dummy variable for all these columns and remove the first column to avoid multicollernaity.\n",
        "  Finally, i have 38 columns."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)\n",
        "There are no text columns in the given dataset which I am working on. So, Skipping this part."
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection\n",
        "\n"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "#Extracting Day of Week column\n",
        "df_cpy.Date=pd.to_datetime(df_cpy.Date,format='%d/%m/%Y')\n",
        "df_cpy['day of week'] = df_cpy['Date'].dt.dayofweek   #0-->Monday 1--->Tuesday and so on"
      ],
      "metadata": {
        "id": "4JAP5PP8spdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a new column weekday/weekend and then removing day of week and date column\n",
        "df_cpy['Weekday/Weekend']=df_cpy['day of week'].apply(lambda x:1 if x==5 or x==6 else 0)\n",
        "df_cpy.drop(['day of week','Date'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "eMI7_2GluAy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking shape of data\n",
        "df_cpy.info()"
      ],
      "metadata": {
        "id": "hUnLv9tgzkNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have fetched 'Weekday/Weekend' column from the Date column and remove the date column .Now I have 38 columns."
      ],
      "metadata": {
        "id": "Bj5YOcGRH44G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "corr = df_cpy.corr()\n",
        "cmap = cmap=sn.diverging_palette(5, 250, as_cmap=True)\n",
        "\n",
        "def magnify():\n",
        "    return [dict(selector=\"th\",\n",
        "                 props=[(\"font-size\", \"7pt\")]),\n",
        "            dict(selector=\"td\",\n",
        "                 props=[('padding', \"0em 0em\")]),\n",
        "            dict(selector=\"th:hover\",\n",
        "                 props=[(\"font-size\", \"12pt\")]),\n",
        "            dict(selector=\"tr:hover td:hover\",\n",
        "                 props=[('max-width', '200px'),\n",
        "                        ('font-size', '12pt')])\n",
        "]\n",
        "\n",
        "corr.style.background_gradient(cmap, axis=1)\\\n",
        "    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
        "    .set_caption(\"Hover to magify\")\\\n",
        "    .set_precision(2)\\\n",
        "    .set_table_styles(magnify())\n"
      ],
      "metadata": {
        "id": "iR9Mi4Bv3i2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "#Checking Multicollinearity via VIF\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        " \n",
        "   # Calculating VIF\n",
        "   vif = pd.DataFrame()\n",
        "   vif[\"variables\"] = X.columns\n",
        "   vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        " \n",
        "   return(vif)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking VIF of all the columns\n",
        "calc_vif(df_cpy[[i for i in df_cpy.describe().columns]])"
      ],
      "metadata": {
        "id": "NeyveUdTrTPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking VIF after removing Dew Point Temperature as having high VIF value and low correlation with the dependent variable\n",
        "calc_vif(df_cpy[[i for i in df_cpy.describe().columns if i not in['Dew_point_temperature']]])"
      ],
      "metadata": {
        "id": "OLvFQvRwIjtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove column Holiday as well having high VIF and check VIF again\n",
        "calc_vif(df_cpy[[i for i in df_cpy.describe().columns if i not in['Dew_point_temperature','Holiday']]])"
      ],
      "metadata": {
        "id": "wKpwVAeIJG4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove column Functioning day having high VIF value and check VIF again\n",
        "calc_vif(df_cpy[[i for i in df_cpy.describe().columns if i not in['Dew_point_temperature','Holiday','Functioning_day']]])"
      ],
      "metadata": {
        "id": "dkPlwmNVJYRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally remove Humidity column having high VIF value and calculate VIF again\n",
        "calc_vif(df_cpy[[i for i in df_cpy.describe().columns if i not in['Dew_point_temperature','Holiday','Functioning_day','Humidity']]])"
      ],
      "metadata": {
        "id": "2iXXRr2xxGIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing all the columns having high VIF from the dataset\n",
        "df_cpy.drop(['Dew_point_temperature','Holiday','Functioning_day','Humidity'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "1XTNqgny7OhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now all features have VIF<10 \n",
        "calc_vif(df_cpy[[i for i in df_cpy.describe().columns]])"
      ],
      "metadata": {
        "id": "VSfz8RvNkLtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#heatmap\n",
        "corr = df_cpy.corr()\n",
        "cmap = cmap=sn.diverging_palette(5, 250, as_cmap=True)\n",
        "\n",
        "def magnify():\n",
        "    return [dict(selector=\"th\",\n",
        "                 props=[(\"font-size\", \"7pt\")]),\n",
        "            dict(selector=\"td\",\n",
        "                 props=[('padding', \"0em 0em\")]),\n",
        "            dict(selector=\"th:hover\",\n",
        "                 props=[(\"font-size\", \"12pt\")]),\n",
        "            dict(selector=\"tr:hover td:hover\",\n",
        "                 props=[('max-width', '200px'),\n",
        "                        ('font-size', '12pt')])\n",
        "]\n",
        "\n",
        "corr.style.background_gradient(cmap, axis=1)\\\n",
        "    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
        "    .set_caption(\"Hover to magify\")\\\n",
        "    .set_precision(2)\\\n",
        "    .set_table_styles(magnify())\n"
      ],
      "metadata": {
        "id": "h932IFIG5sqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have dropped columns having multicolinearity and validate through VIF.Feature Selector that removes all low variance features. This feature selection algorithm looks only at the features(X), not the desired outputs(Y), and can be used for unsupported learning.\n",
        "\n",
        "A Pearson correlation is a number between -1 and 1 that indicates the extent to which two variables are linearly related. The Pearson correlation is also known as the “product moment correlation coefficient” (PMCC) or simply “correlation”\n",
        "\n",
        "Pearson correlations are suitable only for metric variables The correlation coefficient has values between -1 to 1\n",
        "\n",
        "• A value closer to 0 implies weaker correlation (exact 0 implying no correlation)\n",
        "\n",
        "• A value closer to 1 implies stronger positive correlation\n",
        "\n",
        "• A value closer to -1 implies stronger negative correlation\n",
        "\n",
        "Collinearity is the state where two variables are highly correlated and contain similar information about the variance within a given dataset. To detect collinearity among variables, simply create a correlation matrix and find variables with large absolute values.\n",
        "\n",
        "Steps for Implementing VIF\n",
        "\n",
        "• Calculate the VIF factors.\n",
        "\n",
        "• Inspect the factors for each predictor variable, if the VIF is between 5–10, multicollinearity is likely present and you should consider dropping the variable which is least correlated with the target variable.\n",
        "\n",
        "In VIF method, we pick each feature and regress it against all of the other features. For each regression, the factor is calculated as :\n",
        "\n",
        "VIF=\\frac{1}{1-R^2}\n",
        "\n",
        "Where, R-squared is the coefficient of determination in linear regression. Its value lies between 0 and 1.\n",
        "\n",
        "Using pearson corelation I removed the columns having multicolinearity and again validate the VIFs for each feature and found some features having VIF of more than 10  again manipulated some features and again dropped multicolinear columns to make the VIF less than 10. The features got decreased from 38 to 34. "
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above data, Temperature,Dew point temperature have very high VIF value so i decided to remove Dew_point_temperature as it is less correlated to the dependent variable in comparison to Temperature\tand calculate VIF again.\n",
        "Then I removed Holiday,Functioning day and Humidity column sequentially as having high VIF values and less correlated with the target variable."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# Getting symmetric and skew symmetric (positive and negative)features from the columns\n",
        "symmetric_feature=[]\n",
        "pos_sk=[]\n",
        "neg_sk=[]\n",
        "for i in df_cpy.describe().columns:\n",
        "  if abs(df_cpy[i].mean()-df_cpy[i].median())<0.1:\n",
        "    symmetric_feature.append(i)\n",
        "  else:\n",
        "    if (df_cpy[i].skew())>0:\n",
        "      pos_sk.append(i)\n",
        "    else:\n",
        "      neg_sk.append(i)\n",
        "\n",
        "# Getting Symmetric Distributed Features\n",
        "print(\"Symmetric Distributed Features : -\",symmetric_feature)\n",
        "\n",
        "# Getting Skew Symmetric Distributed Features\n",
        "#print(\"Skew Symmetric Distributed Features : -\",non_symmetric_feature)\n",
        "print(\"Ps skew\",pos_sk)\n",
        "print(\"ng skew\",neg_sk)"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "for i in pos_sk[1:]:# Removing Rented bike count column from the list as it's an important factor which can't be treated as outliers here \n",
        "  df_cpy[i]=np.log(max(df_cpy[i]+1) - df_cpy[i])\n",
        "  \n",
        "df_cpy['Temperature']=np.square(max(df_cpy['Temperature']+1)-df_cpy['Temperature'])\n",
        "df_cpy['Visibility']=np.square(max(df_cpy['Visibility']+1)-df_cpy['Visibility'])\n"
      ],
      "metadata": {
        "id": "R5N2v75JrFLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing code of hist plot for each columns to know the data distibution\n",
        "for col in pos_sk[1:]:\n",
        "  fig=plt.figure(figsize=(9,6))\n",
        "  ax=fig.gca()\n",
        "  feature= (df_cpy[col])\n",
        "  sn.distplot(df_cpy[col])\n",
        "  ax.axvline(feature.mean(),color='magenta', linestyle='dashed', linewidth=2)\n",
        "  ax.axvline(feature.median(),color='cyan', linestyle='dashed', linewidth=2)\n",
        "  ax.set_title(col)\n",
        "plt.show()\n",
        "fig=plt.figure(figsize=(9,6))\n",
        "ax=fig.gca()\n",
        "sn.distplot(df_cpy['Visibility'])\n",
        "ax.axvline(df_cpy['Visibility'].mean(),color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(df_cpy['Visibility'].median(),color='cyan', linestyle='dashed', linewidth=2)\n",
        "ax.set_title(\"Visibility\")\n",
        "plt.show()\n",
        "fig=plt.figure(figsize=(9,6))\n",
        "ax=fig.gca()\n",
        "sn.distplot(df_cpy['Temperature'])\n",
        "ax.axvline(df_cpy['Temperature'].mean(),color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(df_cpy['Temperature'].median(),color='cyan', linestyle='dashed', linewidth=2)\n",
        "ax.set_title(\"Temperature\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0NG28yqc8_9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?\n",
        "Surely the data should be tranformed to approx Guassian Distribution which is good for prediction.\n",
        "From the features, I got to know that there are some features which aren't symmetric either positive skewed or negative skewed so aren't following gaussian distribution and rest are having symmetric curve. Thus, for negative skewed columns I have used power(cube) transformation and for positve skewed i have used cube root transformation to achieve gaussian distribution.\n",
        "\n",
        "I tried with other transformations and found this result best for my dataset."
      ],
      "metadata": {
        "id": "noDPUApjT72f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Created X and y dataset\n",
        "X_cols=df_cpy.copy()\n",
        "y=df_cpy.Rented_Bike_Count\n",
        "X_cols.drop('Rented_Bike_Count',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "tKIZlB5mIcei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit(X_cols)\n",
        "X= X.transform(X_cols)"
      ],
      "metadata": {
        "id": "aAQjxw6JGWFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizing the distribution of Target feature\n",
        "y=np.sqrt(y)"
      ],
      "metadata": {
        "id": "dv89Iq2jz39X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?\n",
        "I have used Standard Scalar in my project as the data values follows Normal Distribution. Standardization is a scaling technique wherein it makes the data scale-free by converting the statistical distribution of the data into the below format:\n",
        "mean - 0 (zero)\n",
        "standard deviation - 1\n"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As per my knowledge, for this dataset dimensionality reduction is not required.\n",
        "Dimensionality reduction is the process of reducing the number of features in a dataset while retaining as much information as possible.\n",
        "This can be done to reduce the complexity of a model, improve the performance of a learning algorithm, or make it easier to visualize the data.\n",
        "Techniques for dimensionality reduction include: principal component analysis (PCA), singular value decomposition (SVD), and linear discriminant analysis (LDA).\n"
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# split into 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two competing concerns: with less training data, your parameter estimates have greater variance. With less testing data, your performance statistic will have greater variance. Broadly speaking you should be concerned with dividing data such that neither variance is too high, which is more to do with the absolute number of instances in each category rather than the percentage.\n",
        "\n",
        "If you have a total of 100 instances, you're probably stuck with cross validation as no single split is going to give you satisfactory variance in your estimates. If you have 100,000 instances, it doesn't really matter whether you choose an 80:20 split or a 90:10 split (indeed you may choose to use less training data if your method is particularly computationally intensive).\n",
        "\n",
        "You'd be surprised to find out that 80/20 is quite a commonly occurring ratio, often referred to as the Pareto principle. \n",
        "\n",
        "In this case the training dataset is small, that's why I have taken 70:30 ratio."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I don't think so that the data is imbalanced. Usually this problem occurs in classificaion problem.\n",
        "Imbalanced data refers to those types of datasets where the target class has an uneven distribution of observations, i.e one class label has a very high number of observations and the other has a very low number of observations. \n",
        "Data "
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating function for Mean Squared Error,Mean_Absolute_Error and Root Mean Squared Error \n",
        "#r2 and adjusted r2\n",
        "def metric_score_chart(y_pred,y_test):\n",
        "  MSE  = mean_squared_error(np.square(y_test),np.square(y_pred))\n",
        "  print(\"MSE :\" , MSE)\n",
        "\n",
        "  MAE=mean_absolute_error(np.square(y_test), np.square(y_pred))\n",
        "  print(\"MAE :\" ,MAE)\n",
        "\n",
        "  RMSE = np.sqrt(MSE)\n",
        "  print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "  r2 = r2_score(np.square(y_test), np.square(y_pred))\n",
        "  print(\"R2 :\" ,r2)\n",
        "  print(\"Adjusted R2 : \",1-(1-r2_score(np.square(y_test), np.square(y_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "PLxvofcmUx4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function to plot the comparison between actual values and predictions\n",
        "def plot_comparison(y_pred,model):\n",
        "   plt.figure(figsize=(8,7))\n",
        "   plt.title(\"The comparison of actual values and predictions obtained by \"+model) \n",
        "   plt.plot(np.array((y_test)))\n",
        "   plt.plot((y_pred),color='red')\n",
        "   plt.legend([\"Actual\",\"Predicted\"])\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "fEqFPmueU4RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "reg.score(X_train, y_train)#score of success of Train dataset"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on test data\n",
        "y_pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "v27T5iVa6I5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.intercept_"
      ],
      "metadata": {
        "id": "mbxnzzoVUo7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "id": "HFGSC80G_0o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling function metric score chart\n",
        "metric_score_chart(y_pred,y_test)"
      ],
      "metadata": {
        "id": "h3d6p3v2U__w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling the function plot_comparison\n",
        "plot_comparison(y_pred,'Linear Regression')"
      ],
      "metadata": {
        "id": "-5AgOZZfQH_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Actual v/s Predicted values of test data \n",
        "plt.scatter(np.square(y_test), np.square(y_pred))\n",
        "plt.xlabel('Actual rented bike count')\n",
        "plt.ylabel(\"Predicted bike count\")"
      ],
      "metadata": {
        "id": "dBKQqbsfQQFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resuldual Analysis\n",
        "fig=plt.figure(figsize=(8,8))\n",
        "sn.distplot((np.square(y_test)- np.square(y_pred)),bins=20,color='r')\n",
        "\n",
        "#Plot Label\n",
        "fig.suptitle('Residual Analysis', fontsize = 20) "
      ],
      "metadata": {
        "id": "LC24Lp7nQYHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter(np.square(y_pred),np.square(y_test)-np.square(y_pred),c='r')\n",
        "plt.xlabel('Predicted Rented Bike Count')\n",
        "plt.ylabel('residuals')"
      ],
      "metadata": {
        "id": "rbzvRXpSQdvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation metric Score for Linear Regression\n",
        "\n",
        "*   MSE : 165944.63439815154\n",
        "*   MAE : 283.3135015904589\n",
        "*   RMSE : 407.3630253203542\n",
        "*   R2 : 0.5932138175968089\n",
        "*   Adjusted R2 :  0.5880388199023967 "
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 Lasso Regressor"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the Lasso model on the train dataset\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso  = Lasso(alpha=0.005 , max_iter= 3000)\n",
        "lasso.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Z2rqD_rG9q6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "sQ2a6UZd9y7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on test data\n",
        "y_pred_l = lasso.predict(X_test)"
      ],
      "metadata": {
        "id": "ScO1ckxG9_L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling function metric score chart\n",
        "metric_score_chart(y_pred_l,y_test)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling the function plot_comparison\n",
        "plot_comparison(y_pred_l,'Linear Regression')"
      ],
      "metadata": {
        "id": "7CSMRylFQuLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Actual v/s Predicted test data\n",
        "plt.scatter(np.square(y_test), np.square(y_pred_l))\n",
        "plt.xlabel('Actual rented bike count')\n",
        "plt.ylabel(\"Predicted bike count\")"
      ],
      "metadata": {
        "id": "pv6F7xdKE2X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resuldual Analysis\n",
        "fig=plt.figure(figsize=(8,8))\n",
        "sn.distplot((np.square(y_test)- np.square(y_pred_l)),bins=20,color='r')\n",
        "\n",
        "#Plot Label\n",
        "fig.suptitle('Residual Analysis', fontsize = 20) "
      ],
      "metadata": {
        "id": "DjfDZD-FFKiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter(np.square(y_pred_l),np.square(y_test)-np.square(y_pred_l),c='r')\n",
        "plt.xlabel('Predicted Rented Bike Count')\n",
        "plt.ylabel('residuals')"
      ],
      "metadata": {
        "id": "S2BySTg9Ftip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Hyperprarameter tuning\n",
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "lasso_regressor.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"
      ],
      "metadata": {
        "id": "rKIWC6hfSNBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lasso = lasso_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "nSIHOVVVStym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling function metric score chart\n",
        "metric_score_chart(y_pred_lasso,y_test)"
      ],
      "metadata": {
        "id": "CfFksP8ZS7LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used GridSearchCV optimization technique as it tries all the combinations of the values passed in the dictionary and evaluates the model for each combination using the Cross-Validation method. Hence after using this function we get accuracy/loss for every combination of hyperparameters and we can choose the one with the best performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   MSE : 166302.309942248\n",
        "*   MAE : 283.5389611786305\n",
        "*   RMSE : 407.80180227930333\n",
        "*   R2 : 0.5923370343874592\n",
        "*   Adjusted R2 :  0.5871508825504455\n",
        "From Linear regression there is no improvement in r2 so can say model is performing same as before for alpha value .0001."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE,MAE,RMSE metrics calculate the errors between actual-predicted.R2 score signifies that how much model is performing in comparison to the baseline model"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model 3- Ridge Regression"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "ridge  = Ridge(alpha=0.1)\n",
        "# Fit the Algorithm\n",
        "ridge.fit(X_train,y_train)\n",
        "ridge.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "y_pred_r = ridge.predict(X_test)"
      ],
      "metadata": {
        "id": "7ce-cmGWAEcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling function metric score chart\n",
        "metric_score_chart(y_pred_r,y_test)"
      ],
      "metadata": {
        "id": "kdw8Gk-GAJR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling the function plot_comparison\n",
        "plot_comparison(y_pred_r,'Linear Regression')"
      ],
      "metadata": {
        "id": "WRn-SceUP9ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Actual v/s Predicted test data\n",
        "plt.scatter(np.square(y_test), np.square(y_pred_r))\n",
        "plt.xlabel('Actual rented bike count')\n",
        "plt.ylabel(\"Predicted bike count\")"
      ],
      "metadata": {
        "id": "h5W_udogP9ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resuldual Analysis\n",
        "fig=plt.figure(figsize=(8,8))\n",
        "sn.distplot((np.square(y_test)- np.square(y_pred_r)),bins=20,color='r')\n",
        "\n",
        "#Plot Label\n",
        "fig.suptitle('Residual Analysis', fontsize = 20) "
      ],
      "metadata": {
        "id": "kwHtfpb4P9ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter(np.square(y_pred_r),np.square(y_test)-np.square(y_pred_r),c='r')\n",
        "plt.xlabel('Predicted Rented Bike Count')\n",
        "plt.ylabel('residuals')"
      ],
      "metadata": {
        "id": "eFrvKL8zP9cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here,we got the same result as with Lasso regression."
      ],
      "metadata": {
        "id": "HBh17MTAcERg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "NSor-RKHc6ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Hyperprarameter tuning\n",
        "ridge = Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "# Fit the Algorithm\n",
        "ridge_regressor.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "vH5YHoUvc6y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
      ],
      "metadata": {
        "id": "3r-42Vsvc6y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "y_pred_ridge = ridge_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "Qfjc_-Ubc6y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling function metric score chart\n",
        "metric_score_chart(y_pred_ridge,y_test)"
      ],
      "metadata": {
        "id": "5psrtuLNc6y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we got the same result as in case of Lasso regression (no improvement)"
      ],
      "metadata": {
        "id": "ZPZ4UdZYdNrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model 4- RandomForest Regression"
      ],
      "metadata": {
        "id": "M1tozpZZeUZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation\n",
        "rand_forest = RandomForestRegressor()\n",
        "\n",
        "parameters = {'n_estimators' : [int(x) for x in np.linspace(start=10,stop=20, num=5)], \n",
        "             'max_depth' : [10,15,20],\n",
        "             'min_samples_split':[2,4],\n",
        "             'min_samples_leaf':[1,2],\n",
        "             'bootstrap' : [True,False]\n",
        "             }\n",
        "\n",
        "rf_model_grid = GridSearchCV(rand_forest,parameters,scoring='r2',cv=5)\n",
        "# Fit the Algorithm\n",
        "rf_model_grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "9aU0Dn5ieTbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the best parameters for Random Forest regression fetched through GridSearchCV\n",
        "print(f'The best value for parameters in random forest regression through GridSearchCV is found to be {rf_model_grid.best_params_}')\n",
        "print(f'\\nUsing {rf_model_grid.best_params_} as the value for the parameters in random forest model, it gives us a negative mean squared error of: {rf_model_grid.best_score_}')"
      ],
      "metadata": {
        "id": "cPqVpGZ9ev_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting Random Forest model on the dataset with appropriate paramter values\n",
        "rf_model = RandomForestRegressor(bootstrap=True,max_depth=20,min_samples_leaf=2,min_samples_split=4,n_estimators=15).fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "yenYn5-1Swg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting values of the independent variable on the test set\n",
        "Y_test_pred_rf = rf_model_grid.predict(X_test)"
      ],
      "metadata": {
        "id": "XA01Hd0GeyI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "0vWIUhaJfA1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling function metric score chart\n",
        "metric_score_chart(Y_test_pred_rf,y_test)"
      ],
      "metadata": {
        "id": "9YFnRQ0DCcz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here also I have used GridSearchCv as it tries all the combinations of the values passed in the dictionary and evaluates the model for each combination using the Cross-Validation method. Hence after using this function we get accuracy/loss for every combination of hyperparameters and we can choose the one with the best performance."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   MSE : 100277.97171403009\n",
        "*   MAE : 184.34893352694257 \n",
        "*   RMSE : 316.66697288165386\n",
        "*   R2: 0.754184921732306\n",
        "*   Adjusted R2 :  0.7510577445608203 \n",
        "\n",
        "Yes in this model r2 and adjusted r2 is increased drastically from 0.59 to 0.75.\n",
        "MSE, MAE and RMSE is also decreased significantly."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I like to choose MSE,MAE and RMSE metrics as the indicated the possible outcome of errors.\n",
        "But r2 and adjusted r2 shows the clear picture of performance as it compares the result with the baseline model."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have Random Forest Regressor as the best model as\n",
        "Random Forest Regression is a supervised learning algorithm that uses ensemble learning method for regression. Ensemble learning method is a technique that combines predictions from multiple machine learning algorithms to make a more accurate prediction than a single model."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model explainability refers to the concept of being able to understand the machine learning model. For example – If a healthcare model is predicting whether a patient is suffering from a particular disease or not. The medical practitioners need to know what parameters the model is taking into account or if the model contains any bias. So, it is necessary that once the model is deployed in the real world. Then, the model developers can explain the model.\n",
        "\n",
        "Popular techniques for model explainability:\n",
        "\n",
        "LIME\n",
        "SHAP\n",
        "ELI-5\n",
        "In this project I'll be using SHAP for model explainability. Among the various methods in SHAP I'll be using the SHAP summary plot, which plots features/columns in order of their impact on the predictions and also plots the SHAP values."
      ],
      "metadata": {
        "id": "3GgrRPURYBnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing the shap library\n",
        "!pip install shap"
      ],
      "metadata": {
        "id": "4sY5QVpVX3ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialising javascript for visualisation of SHAP\n",
        "import shap"
      ],
      "metadata": {
        "id": "Mk-CbZzJYUjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function to plot the shap summary plot\n",
        "def shap_summary(model):\n",
        "   explainer_shap = shap.Explainer(model=model, masker=X_train)\n",
        "   shap_values = explainer_shap.shap_values(X_train)\n",
        "   shap.summary_plot(shap_values,X_train,feature_names=X_cols.columns)"
      ],
      "metadata": {
        "id": "aoVB4EsUYaG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting shap summary plot for linear regression\n",
        "shap_summary(reg)"
      ],
      "metadata": {
        "id": "OqBDo2LBY0Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting shap summary plot for lasso regression\n",
        "shap_summary(lasso)"
      ],
      "metadata": {
        "id": "bVdBa4CYPN_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting shap summary plot for Ridge regression\n",
        "shap_summary(ridge)"
      ],
      "metadata": {
        "id": "I3ezjBU9PRo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting shap summary plot for Random forest regression model\n",
        "explainer_shap = shap.Explainer(model=rf_model, masker=X_train)\n",
        "shap_values = explainer_shap.shap_values(X_train,check_additivity=False)\n",
        "shap.summary_plot(shap_values,X_train,feature_names=X_cols.columns)"
      ],
      "metadata": {
        "id": "NcU0EB4kQ-9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that different importance or impact power is given to the features by each model and that defines how well the model performs on prediction. Random forest gives almost all the features a significant impact power and therefore it performs the best out of all the 4 models.\n",
        "\n",
        "By looking at the SHAP summary plot for each model, we can figure out the feature importance and also its impact power by understanding the SHAP values."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "PbUPb-GxXisD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "with open(\"model_pickle\",\"wb\")as f:\n",
        "  pickle.dump(rf_model,f)\n",
        "  "
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "with open(\"model_pickle\",\"rb\")as f:\n",
        "  model=pickle.load(f)"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=model.predict([[10000,1,1,1,3,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1]])\n",
        "#Square the result to get actual result\n",
        "res=np.square(res)\n",
        "print(int(res))"
      ],
      "metadata": {
        "id": "h8abW5FNhKjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "EDA insights:<br>\n",
        "Most number of bikes are rented in the Summer season and the lowest in the winter season.<br>\n",
        "There is no bike demand on non Functioning day.<br>\n",
        "Most number of bikes are rented in the temperature range of 15 degrees to 30 degrees.<br>\n",
        "Most number of bikes are rented when there is no snowfall or rainfall.<br>\n",
        "Majority of the bikes are rented for a humidity percentage range of 30 to 70.<br>\n",
        "The highest number of bike rentals have been done in the 18th hour, i.e 6pm, and lowest in the 4th hour, i.e 4am.<br>\n",
        "Most of the bike rentals have been made when there is high visibility.<br><br>\n",
        "\n",
        "Results from ML models:<br>\n",
        "Random Forest Regression is the best performing model with an r2 score of 0.75.<br>\n",
        "Linear Regression,Lasso Regression(L1 regularization) and Ridge Regression are performing the same with an r2 score of 0.59.<br>\n",
        "Actual vs Prediction visualisation is done for all the 4 models with cv technique.<br>\n",
        "All 4 models have been explained with the help of SHAP library.<br>\n",
        "Temperature is the most important factor according to all the models.<br><br>\n",
        "Challenges faced:<br>\n",
        "Removing Outliers.<br>\n",
        "Encoding the categorical columns.<br>\n",
        "Removing Multicollinearity from the dataset.<br>\n",
        "Choosing Model explainability technique."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}